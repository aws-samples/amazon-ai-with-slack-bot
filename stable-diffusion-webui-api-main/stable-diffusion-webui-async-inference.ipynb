{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c774a659",
   "metadata": {},
   "source": [
    "Here we will show you how to use stable-diffusion-webui to generate image with Lora and ControlNet support. The stable-diffusion-webui will be hostd at Amazon SageMaker Async endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6016ec68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afbb91",
   "metadata": {},
   "source": [
    "Prepare models directory and organize the structure as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95481c68-3b3c-4138-b794-ff2d9583b977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p models\n",
    "!mkdir -p models/Stable-diffusion\n",
    "!mkdir -p models/ControlNet\n",
    "!mkdir -p models/Lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246b642",
   "metadata": {},
   "source": [
    "Logout from AWS public ECR to avoid the authentication token is expired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker logout public.ecr.aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a615bee",
   "metadata": {},
   "source": [
    "Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788db8d-3b69-4807-b83e-eaff32195190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./build_and_push.sh.lite $region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdc938",
   "metadata": {},
   "source": [
    "Install Huggingface Hub toolkit and login with your Huggingface access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f1a33-f2b3-41a5-a5ad-fcfb2d90e2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install huggingface_hub\n",
    "!huggingface-cli login --token [Your-huggingface-access-token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7577b6e",
   "metadata": {},
   "source": [
    "Download Stable-diffuion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e6085-3a8b-452d-87f8-6f820ffd75d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-2-1\", \n",
    "    filename=\"v2-1_768-ema-pruned.ckpt\", \n",
    "    local_dir=\"models/Stable-diffusion/\"\n",
    ")\n",
    "hf_hub_download(\n",
    "    repo_id=\"runwayml/stable-diffusion-v1-5\", \n",
    "    filename=\"v1-5-pruned.ckpt\", \n",
    "    local_dir=\"models/Stable-diffusion/\"\n",
    ")\n",
    "!wget \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\" -O models/Stable-diffusion/v2-1_768-ema-pruned.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0d6a6",
   "metadata": {},
   "source": [
    "Download ControlNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3f273-60b8-4ed9-bb8c-eea7762b3f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_hub_download(\n",
    "    repo_id=\"lllyasviel/ControlNet\", \n",
    "    filename=\"models/control_sd15_canny.pth\", \n",
    "    local_dir=\"models/ControlNet/\"\n",
    ")\n",
    "!mv models/ControlNet/models/control_sd15_canny.pth models/ControlNet/control_sd15_canny.pth\n",
    "!rm -rf models/ControlNet/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0680f7",
   "metadata": {},
   "source": [
    "Download Lora model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e1108-2cb4-42fa-9bc5-744ec226fa0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget \"https://civitai.com/api/download/models/7627\" -O models/Lora/2bNierAutomataLora_v2b.safetensors\n",
    "\n",
    "hf_hub_download(\n",
    "    repo_id=\"andite/anything-v4.0\", \n",
    "    filename=\"anything-v4.5-pruned.safetensors\", \n",
    "    local_dir=\"models/Lora/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097e342",
   "metadata": {},
   "source": [
    "Compress Stable-diffusion, ControlNet and Lora models as tar.gz archieve file when models/model.tar.gz doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c5ec6-03f3-4aed-ba43-d266dc04ee67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "![ ! -f models/model.tar.gz ] && cd models && tar czvfh model.tar.gz Stable-diffusion ControlNet Lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13f13b",
   "metadata": {},
   "source": [
    "Download s5cmd which is a very fast S3 and local filesystem execution tool and place it under directory - tools/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d286b5c-a500-4010-b8ae-b6fd8fc1338f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz -O tools/s5cmd_2.0.0_Linux-64bit.tar.gz\n",
    "!tar xzvf tools/s5cmd_2.0.0_Linux-64bit.tar.gz -C tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c2023",
   "metadata": {},
   "source": [
    "Upload file - models/model.tar.gz to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd21e8a1-86c4-4f83-98a4-cdb5204aa9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = \"s3://{0}/stable-diffusion-webui/data/model.tar.gz\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce51bd-2c29-4494-ab81-e96cfb9ba712",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tools/s5cmd cp models/model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d24f73-e016-4b16-b5b2-cefb51e356a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = None\n",
    "image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-inference-api:latest'.format(account_id, region_name)\n",
    "base_name = sagemaker.utils.base_name_from_image(image_uri)\n",
    "model_environment = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT': '1200',\n",
    "    'ckpt': '/opt/ml/model/Stable-diffusion/v1-5-pruned'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d421d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4da136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "instance_type = 'ml.g4dn.2xlarge'\n",
    "instance_count = 1\n",
    "async_config = AsyncInferenceConfig(output_path='s3://{0}/{1}/asyncinvoke/out/'.format(bucket, 'stable-diffusion-webui'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3ab80",
   "metadata": {},
   "source": [
    "Here we use Async inference since Async inference is more suitable for workloads with large payload sizes and long inference processing times. Async inference also works for stable-diffusion-webui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb508a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type, \n",
    "    initial_instance_count=instance_count,\n",
    "    async_inference_config=async_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bdd67",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab39c9a4-7f96-42f1-8bec-cc02bc1b51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find('/', 5)\n",
    "    bucket = s3uri[5 : pos]\n",
    "    key = s3uri[pos + 1 : ]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54519ea",
   "metadata": {},
   "source": [
    "LoRA (Low-Rank Adaptation of Large Language Models) models have become the standard to extend the Stable Diffusion models. Let's use Lora model to generate images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d00e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    'task': 'text-to-image', \n",
    "    'model': 'v1-5-pruned.ckpt',\n",
    "    'txt2img_payload': {\n",
    "        'enable_hr': False, \n",
    "        'denoising_strength': 0.7, \n",
    "        'firstphase_width': 0, \n",
    "        'firstphase_height': 0, \n",
    "            'prompt': 'yorha no. 2 type b, 1girl, bangs, black blindfold, black dress, black gloves, black hairband, blindfold, blindfold removed, breasts, cleavage cutout, clothing cutout, commentary request, dress, gloves, hairband, half-closed eyes, hand up, highres, io (sinking=carousel), juliet sleeves, long sleeves, looking at viewer, medium breasts, mole, mole under mouth, nier (series), nier automata, no blindfold, parted lips, puffy sleeves, short hair, solo, thighhighs, turtleneck, upper body, white hair, bokeh <lora:2bNierAutomataLora_v2b:0.5>', \n",
    "        'styles': ['None', 'None'], \n",
    "        'seed': -1.0, \n",
    "        'subseed': -1.0, \n",
    "        'subseed_strength': 0, \n",
    "        'seed_resize_from_h': 0, \n",
    "        'seed_resize_from_w': 0, \n",
    "        'sampler_index': 'DPM++ SDE Karras', \n",
    "        'batch_size': 1, \n",
    "        'n_iter': 1, \n",
    "        'steps': 20, \n",
    "        'cfg_scale': 7, \n",
    "        'width': 512, \n",
    "        'height': 512, \n",
    "        'restore_faces': False, \n",
    "        'tiling': False, \n",
    "        'negative_prompt': '(worst quality, low quality:1.3)', \n",
    "        'eta': 1, \n",
    "        's_churn': 0, \n",
    "        's_tmax': None, \n",
    "        's_tmin': 0, \n",
    "        's_noise': 1, \n",
    "        'override_settings': {}, \n",
    "        'script_args': [0, False, False, False, \"\", 1, \"\", 0, \"\", True, False, False]}\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789711d",
   "metadata": {},
   "source": [
    "Wait until the async inference is done in case we use async inferece for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0b78b-ecd4-4e3c-bae0-c32d2a2d3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "  max_attempts=100, #  number of attempts\n",
    "  delay=10 #  time in seconds to wait between attempts\n",
    "  )\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5ee14-5c6d-442a-ac76-98663b799283",
   "metadata": {},
   "source": [
    "Process the generated images from async inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea512f5b-da4f-47e5-8198-ecfd644d80b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import base64\n",
    "from datetime import datetime\n",
    "try:\n",
    "    bucket, key = get_bucket_and_key(prediction.output_path)\n",
    "    obj = s3_resource.Object(bucket, key)\n",
    "    body = obj.get()['Body'].read().decode('utf-8') \n",
    "    for image in json.loads(body)['images']:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(image)))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(\"%Y%m%d%H%M%S.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d880cf",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7675b7-cbb1-4343-9964-c9c6534aac38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        image.save(output_bytes, format=\"JPEG\")\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "    \n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "    \n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = 'image/jpeg'\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\"\n",
    "        + (mimetype if mimetype is not None else \"\")\n",
    "        + \";base64,\"\n",
    "        + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171d989-446c-4c78-8e8c-67eb1673376d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = Image.open(\"./images/inference/ControlNet/bal-source.png\").convert('RGB')\n",
    "size = image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b58b8f-1fe3-4c41-9bf4-610e7aaf2292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    'task': 'text-to-image', \n",
    "    'model': 'v1-5-pruned.ckpt',\n",
    "    'txt2img_payload': {\n",
    "        'alwayson_scripts': {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"none\",\n",
    "                        \"model\": \"control_sd15_canny [fef5e48e]\",\n",
    "                        \"weight\": 1,\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"invert_image\": False,\n",
    "                        \"resize_mode\": \"Scale to Fit (Inner Fit)\", \n",
    "                        \"rgbbgr_mode\": False, \n",
    "                        \"low_vram\": False, \n",
    "                        \"processor_res\": 64, \n",
    "                        \"threshold_a\": 64, \n",
    "                        \"threshold_b\": 64, \n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1, \n",
    "                        \"guess_mode\": False, \n",
    "                        \"scribble_mode\": False\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'enable_hr': False, \n",
    "        'denoising_strength': 0.7, \n",
    "        'firstphase_width': 0, \n",
    "        'firstphase_height': 0, \n",
    "        'prompt': 'ballon', \n",
    "        'styles': ['None', 'None'], \n",
    "        'seed': -1.0, \n",
    "        'subseed': -1.0, \n",
    "        'subseed_strength': 0, \n",
    "        'seed_resize_from_h': 0, \n",
    "        'seed_resize_from_w': 0, \n",
    "        'sampler_index': 'Euler a', \n",
    "        'batch_size': 1, \n",
    "        'n_iter': 1, \n",
    "        'steps': 20, \n",
    "        'cfg_scale': 7, \n",
    "        'width': 512, \n",
    "        'height': 512, \n",
    "        'restore_faces': False, \n",
    "        'tiling': False, \n",
    "        'negative_prompt': '', \n",
    "        'eta': 1, \n",
    "        's_churn': 0, \n",
    "        's_tmax': None, \n",
    "        's_tmin': 0, \n",
    "        's_noise': 1, \n",
    "        'override_settings': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2775d8",
   "metadata": {},
   "source": [
    "Wait until the async inference is done in case we use async inferece for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484ba4e-8691-4c63-ab2f-c8580e5364dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "  max_attempts=100, #  number of attempts\n",
    "  delay=10 #  time in seconds to wait between attempts\n",
    "  )\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38f8ad-b546-4cd2-8f24-86271032cd06",
   "metadata": {},
   "source": [
    "Process the generated images from async inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d24432-044a-4059-a423-652390ff4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import base64\n",
    "from datetime import datetime\n",
    "try:\n",
    "    bucket, key = get_bucket_and_key(prediction.output_path)\n",
    "    obj = s3_resource.Object(bucket, key)\n",
    "    body = obj.get()['Body'].read().decode('utf-8') \n",
    "    for image in json.loads(body)['images']:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(image)))\n",
    "        image.show()\n",
    "        image.save(datetime.now().strftime(\"%Y%m%d%H%M%S.jpg\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fda86",
   "metadata": {},
   "source": [
    "Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04df861",
   "metadata": {},
   "source": [
    "Process the generated images from async inference result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de653c58",
   "metadata": {},
   "source": [
    "[Optional] Create auto scaling group for SageMaker endpoint in case you want to scale it based on particul metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(endpoint_name, min_capcity = 1, max_capcity = 2, target_value = 5):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f'Request-ScalingPolicy-{endpoint_name}',\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600, # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300 # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
